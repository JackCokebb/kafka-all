apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaConnector
metadata:
  name: mongodb-source-connector-j5
  namespace: kafka
  labels:
    # The strimzi.io/cluster label identifies the KafkaConnect instance
    # in which to create this connector. That KafkaConnect instance
    # must have the strimzi.io/use-connector-resources annotation
    # set to true.
    strimzi.io/cluster: kafkaconnect
spec:
  class: com.mongodb.kafka.connect.MongoSourceConnector
  tasksMax: 1
  config:
    connection.uri: "mongodb://haruband:kk3249@mongodb-mongos.mongodb.svc.cluster.local:27017/?authSource=admin&ssl=false"
    database: clever
    collection: dev0-patient
    topic.prefix: jee
    topic.suffix: "5"
    #Copy existing data from source collections 
    #and convert them to Change Stream events on their respective topics
    copy.existing: true
    #Determines which data format the source connector outputs for the value document
    output.format.value: json
    output.format.key: json
    #Only publish the changed document instead of the full change stream document
    #if true, getting the full document in case any create and update operation
    #is done on the MongoDB. but not deletion.
    publish.full.document.only: true
    #Determines what to return for update operations when using a Change Stream. 
    #Update Lookup 옵션을 사용하면, 변경으로 인한 결과 Document도 Change Stream에 함께 전달
    change.stream.full.document: updateLookup
    #An array of objects describing the pipeline operations to run.
    #define a custom aggregation pipeline to filter or modify the change events output.
    # pipeline: >
    # [{"$match":{"operationType":{"$in":["insert","update","replace","delete"]}}},{"$project":{"_id":1,"fullDocument":1}}]

