apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaConnector
metadata:
  name: mongodb-source-connector-j3
  namespace: kafka
  labels:
    # The strimzi.io/cluster label identifies the KafkaConnect instance
    # in which to create this connector. That KafkaConnect instance
    # must have the strimzi.io/use-connector-resources annotation
    # set to true.
    strimzi.io/cluster: kafkaconnect
spec:
  class: com.mongodb.kafka.connect.MongoSourceConnector
  tasksMax: 1
  config:
    connection.uri: "mongodb://username:password@mongodbURI/?authSource=admin&ssl=false"
    database: clever
    #collection: dev0-patient
    topic.prefix: jee
    topic.suffix: test
    #Copy existing data from source collections 
    #and convert them to Change Stream events on their respective topics
    copy.existing: true
    #Determines which data format the source connector outputs for the value document
    output.format.value: schema
    #Only publish the changed document instead of the full change stream document
    publish.full.document.only: false
    #Determines what to return for update operations when using a Change Stream. 
    #if Update Lookup is set, pass the change stream with modified result Documnet also
    change.stream.full.document: updateLookup
    #An array of objects describing the pipeline operations to run.
    #define a custom aggregation pipeline to filter or modify the change events output.
    #select several collections to get data with ns.coll
    pipeline: >
      [{"$match": {"operationType": {"$in": ["insert","update","replace","delete"]}, "ns.coll": {"$regex": /^(dev0-chart|dev0-patient|dev0-receipt)$/}}},{"$project": {"_id": 1,"ns": 1,"operationType": 1,"fullDocument": 1,"updateDescription": 1,"documentKey": 1}}]    


